---
title: "Eric_Hirsch_622_Final_Assignment"
subtitle: "Predicting Sales Data" 
author: "Eric Hirsch"
date: "10/7/2022"
output:
  pdf_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning =  FALSE, message = FALSE)
```

```{r, include=FALSE}
library(devtools)
library(roxygen2)
library(Hmisc)
library(psych)
library(tidyverse)
library(skimr)
library(purrr)
library(tidyr)
library(tidyverse)
library(gridExtra)
library(lubridate)
library(fastDummies)
library(data.table)
library(mltools)
library(MASS)
library(car)
library(patchwork)
library(ggthemes)
library(tinytex)
library(stats)
library(ggsci)
library(scales)
library(naniar)
library(caret)
library(pROC)
library(tidyverse)
library(Hmisc)
library(skimr)
#install.packages("devtools")
devtools::install_github("ericonsi/EHData", force=TRUE)
library(EHData)
library(patchwork)
library(gridExtra)
library(ggsci)
library(caret)
library(pROC)
library(car)
library(psych)
library(patchwork)
library(MASS)
library(lubridate)
library(e1071)
library(caTools)
library(class)
library(keras)
library(mlbench)
library(dplyr)
library(magrittr)
library(neuralnet)
#library(mice)
```

```{r}

#dfTrain <- read.csv("C:\\Users\\erico\\Documents\\R\\Space\\train.csv")
#dfTest <- read.csv("C:\\Users\\erico\\Documents\\R\\Space\\test.csv")

dfTrain <- read.csv("D:\\Rstudio\\Cuny_622\\Space\\train.csv")
dfTest <- read.csv("D:\\Rstudio\\Cuny_622\\Space\\test.csv")

#dfTrain <- read.csv("C:\\Users\\erico\\Documents\\R\\Space\\train.csv")
#dfTest <- read.csv("C:\\Users\\erico\\Documents\\R\\Space\\test.csv")
```


### 1. Data Exploration


#### A. Summary Statistics

```{r}


summary(dfTrain)
str(dfTrain)
dfTrain %>%
  count(dfTrain$Transported)
```


### Look at Distributions


```{r}


a <- EHSummarize_SingleColumn_Histograms(dfTrain3)
grid.arrange(grobs=a[c(1:6)], ncol=3)

EHExplore_OneContinuousAndOneCategoricalColumn_Boxplots(dfTrain3, "Transported")
#grid.arrange(grobs=b[c(1:8)], ncol=1)

EHSummarize_StandardPlots(dfTrain3, "Transported")

```

### Look at Multicollinearity

```{r}

dfNum <- dfTrain %>%
  dplyr::select(where(is.numeric)) 
dfNum <- na.omit(dfNum)

EHExplore_Multicollinearity(dfNum)
```

### Look at Missing Values

```{r}

EHSummarize_MissingValues(dfTrain)

dfMissingRecordsFlagAny <- dfTrain %>%
    mutate(Flag=ifelse(rowSums(is.na(dfTrain)) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
    dplyr::select(Transported, Flag)

dfMissingRecordsFlag_RoomService <- dfTrain %>%
    mutate(RoomServiceFlag=ifelse(is.na(dfTrain$RoomService) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
      dplyr::select(Transported, RoomServiceFlag)


dfMissingRecordsFlag_VRDeck <- dfTrain %>%
    mutate(VRDeckFlag=ifelse(is.na(dfTrain$VRDeck) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
      dplyr::select(Transported, VRDeckFlag)


dfMissingRecordsFlag_SPA <- dfTrain %>%
    mutate(SpaFlag=ifelse(is.na(dfTrain$Spa) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
      dplyr::select(Transported, SpaFlag)


dfMissingRecordsFlag_ShoppingMall <- dfTrain %>%
    mutate(ShoppingMallFlag=ifelse(is.na(dfTrain$ShoppingMall) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
      dplyr::select(Transported, ShoppingMallFlag)


dfMissingRecordsFlag_FoodCourt <- dfTrain %>%
    mutate(FoodCourtFlag=ifelse(is.na(dfTrain$FoodCourt) > 0, 1, 0)) %>%
    mutate(Transported=ifelse(Transported=='True',1,0)) %>%
      dplyr::select(Transported, FoodCourtFlag)

print(chisq.test(table(dfMissingRecordsFlagAny)))
print(chisq.test(table(dfMissingRecordsFlag_SPA)))
print(chisq.test(table(dfMissingRecordsFlag_FoodCourt)))
print(chisq.test(table(dfMissingRecordsFlag_VRDeck)))
print(chisq.test(table(dfMissingRecordsFlag_ShoppingMall)))
print(chisq.test(table(dfMissingRecordsFlag_RoomService)))

```

### First Pass: Logistic regression

```{r}


dfTrainNum <- dfTrain %>%
  mutate(Transported=ifelse(Transported=='True',1,0)) %>%
  dplyr::select(where(is.numeric)) 

dfTestNum <- dfTest %>%
  dplyr::select(where(is.numeric))

dfTestNum <- cbind(dfTestNum, "PassengerID" = dfTest$PassengerId)

q <- EHModel_Regression_Logistic(dfTrainNum, "Transported", returnLM = TRUE)

predictions_logistic <- EHModel_Predict(q, dfTestNum, threshold=.5, testData_IDColumn = "PassengerID", predictionsColumnName = "Transported")

predictions_logistic$Transported <- ifelse(predictions_logistic$Transported==1,"True","False")
write_csv(predictions_logistic, "C://Users//erico//Desktop//LR_FirstPass.csv")

```
### Data Preparation and Feature Engineering
### 1. Create Groups needs to be done before missing values correction since it counts group members

```{r}

Group2 <- dfTrain %>% dplyr::select(PassengerId, Transported) %>% mutate(Transported=ifelse(Transported=='True',1,0))

Group2$Group <- sub("\\_.*", "", Group2$PassengerId)

Group2Sum <- Group2 %>%
  dplyr::group_by(Group) %>%
  dplyr::summarize(PredPercent= sum(Transported)/dplyr::n(), count=dplyr::n())

Group2SumGroups <- Group2Sum %>%
  filter(count>1)

hist(Group2SumGroups$PredPercent)


dfTrainA <- dfTrain

dfTrainA$Group <- Group2$Group

dfTrainAA <- inner_join(dfTrainA, Group2Sum, by="Group") %>% dplyr::select(-Group, -PredPercent)

dfTrainBB <- dfTrainAA %>%
  mutate(Transported = ifelse(Transported=="True",1,0))

boxplot(as.numeric(dfTrainBB$count), as.numeric(dfTrainBB$Transported))

Group2a <- dfTest %>% dplyr::select(PassengerId) 

Group2a$Group <- sub("\\_.*", "", Group2a$PassengerId)

Group2aSum <- Group2a %>%
  dplyr::group_by(Group) %>%
  dplyr::summarize(count=dplyr::n())

dfTestA <- dfTest

dfTestA$Group <- Group2a$Group

dfTestAA <- inner_join(dfTestA, Group2aSum, by="Group") %>% dplyr::select(-Group)

```

### Handle Missing Variables

```{r}
dfTrain1 <- na.omit(dfTrainAA)
#dfTrain1 <- EHPrepare_MissingValues_Imputation(dfTrainAA, impute="median")
dfTest1 <- EHPrepare_MissingValues_Imputation(dfTestAA, impute="median")

```

### Create Cabin variables

```{r}
library(stringr)
dfTrain1$Cabin1 <- substr(dfTrain1$Cabin,1,1)
dfTrain1$Cabin2 <- str_sub(dfTrain1$Cabin, - 1, - 1) 
#dfTrain1$Cabin3 <- as.numeric(gsub(".*?([0-9]+).*", "\\1", dfTrain1$Cabin))

dfTrain2 <- dfTrain1 %>%
  dplyr::select(-Cabin) %>%
  mutate(Transported=ifelse(Transported=="True",1,0))

dfTest1$Cabin1 <- substr(dfTest1$Cabin,1,1)
dfTest1$Cabin2 <- str_sub(dfTest1$Cabin, - 1, - 1) 
#dfTest1$Cabin3 <- as.numeric(gsub(".*?([0-9]+).*", "\\1", dfTest1$Cabin))

dfTest2 <- dfTest1 %>%
  dplyr::select(-Cabin)

dfTrain3 <- dfTrain2
dfTest3 <- dfTest2
```



### Create Dummy Variables

```{r}

dfTrain4 <- dfTrain3 %>%
  dplyr::select(-Name, -PassengerId)

PassengerID <- dfTest3$PassengerId
dfTest4 <- dfTest3 %>%
  dplyr::select(-Name, -PassengerId)

dfTrain5 <- EHPrepare_CreateDummies(dfTrain4, "Transported")
dfTest5 <- EHPrepare_CreateDummies(dfTest4, "Transported")

dfTest5 <- cbind(PassengerID, dfTest5)

dfTrain5Num <- dfTrain5 %>%
  dplyr::select(where(is.numeric)) 


```

```{r}

df5Num <- dfTrain5 %>%
  dplyr::select(where(is.numeric)) 
df5Num <- na.omit(df5Num)

EHExplore_Multicollinearity(df5Num)
```

### Perform Logistic Regression

```{r}
dfTrain5z <- dfTrain5
dfTrain5z$Group = ifelse(dfTrain5z$count>1,1,0)

dfTrain5z$Inter_CountShop = dfTrain5z$Group*dfTrain5z$ShoppingMall
dfTrain5z$Inter_CountAge = dfTrain5z$Group*dfTrain5z$Age #Gets worse for Age and Foodcourt

dfTrain5zz <- dfTrain5z %>%
  dplyr::select(-count)

dfTest5z <- dfTest5
dfTest5z$Group = ifelse(dfTest5z$count>1,1,0)

dfTest5z$Inter_CountShop = dfTest5z$Group*dfTest5z$ShoppingMall
dfTest5z$Inter_CountAge = dfTest5z$Group*dfTest5z$Age #Gets worse for Age and Foodcourt

dfTest5zz <- dfTest5z %>%
  dplyr::select(-count)

q <- EHModel_Regression_Logistic(dfTrain5zz, "Transported", returnLM = TRUE)
predictions_logistic <- EHModel_Predict(q, dfTest5zz, threshold=.5, testData_IDColumn = "PassengerID", predictionsColumnName = "Transported")

predictions_logistic$Transported <- ifelse(predictions_logistic$Transported==1,"True","False")
write_csv(predictions_logistic, "C://Users//erico//Desktop//LR_WithFeatures.csv")

```

### Perform PCA

```{r}


pca <- prcomp(dfTrain5zz, center = TRUE,scale. = TRUE)

summary(pca)
plot(pca)


```



### Perform Random Forest

```{r}
dfSmall <- dfTrain5 %>%
  dplyr::filter(row_number() %% 15 ==1) 

#a <- EHModel_RandomForest(dfTrain5zz, "Transported")  #RESTORE
predictions_rf <- EHModel_Predict(a$rf, dfTest5zz, predictionsColumnName = "Transported", testData_IDColumn = "PassengerID")

predictions_rf$Transported <- ifelse(predictions_rf$Transported==1,"True","False")
write_csv(predictions_rf, "C://Users//erico//Desktop//RF1.csv")
```


Didn't Do This:

```{r}

#install_github("vqv/ggbiplot")
#library(ggbiplot)
#ggbiplot(pca, labels=dfx1$HomePlanet)

```

### Perfomr K-Means

```{r}


library(factoextra)

#fviz_nbclust(dfTrain5zz, kmeans, method = "wss") #RESTORE

k2 <- kmeans(dfTrain5zz, centers=9, iter.max = 10, nstart = 1)
fviz_cluster(k2, data = dfTrain5zz)
```

```{r}

dfNumC <- cbind(dfNum, Cluster = k2$cluster)

dfNumCSum <- dfNumC %>%
  group_by(Cluster) %>%
  dplyr::summarise(across(everything(), mean))

dfNumCSumS <- scale(dfNumCSum)
qq <- as.matrix(dfNumCSumS)

heatmap(qq, Rowv = NA, Colv = NA)

#EHExplore_OneContinuousAndOneCategoricalColumn_Boxplots(dfNumC, "Cluster")
```

### Create a smaller database


```{r}
dfSmall <- dfTrain5 %>%
  dplyr::filter(row_number() %% 2 ==1) 
```

### Perform GBM

```{r}

 #SECOND BEST MODEL!!
library(gbm)
boost=gbm(Transported ~ . ,data = dfTrain5, distribution = "gaussian",n.trees = 10000,
                  shrinkage = 0.01, interaction.depth = 4)
boost

summary(boost) #Summary gives a table of Variable Importance and a plot of Variable Importance

predictions2 <- as.data.frame(predict(boost, dfTest5)) %>%
  rename(Transported = 1) 

result <- as.data.frame(cbind(dfTest5$PassengerID, predictions2$Transported)) %>%
  rename(PassengerID = 1, Transported=2) %>%
  mutate(Transported = ifelse(Transported>.5,'True','False'))



write_csv(result, "C:\\Users\\Eric\\Desktop\\SVMpredictions5.csv")

```

### Perform SVM

```{r}
#svm2 <- EHModel_SVM(dfTrain5zz, "Transported", method="poly") #RESTORE

predictions_svm <- EHModel_Predict(svm2$svm, dfTest5zz, predictionsColumnName = "Transported", testData_IDColumn = "PassengerID")

predictions_svm$Transported <- ifelse(predictions_svm$Transported==1,"True","False")
write_csv(predictions_svm, "C://Users//erico//Desktop//SVMPoly.csv")
```

Perfomr K means

```{r}
library(factoextra)

fviz_nbclust(dfNum, kmeans, method = "wss")

k2 <- kmeans(dfNum, centers=3, iter.max = 10, nstart = 1)
fviz_cluster(k2, data = dfNum)
```

Perform XGBoost - also does some feature engineering
```{r}
library(xgboost)
library(caret)
#BEST MODEL 221106-1123

#need to scale?

#make this example reproducible
set.seed(0)

dfTrain5q <-dfTrain5
dfTest5q <- dfTest5

dfTrain5q$Transported = as.character(dfTrain5q$Transported)
dfTrain5$Transported = as.character(dfTrain5$Transported)

dfTrain5q$Group = ifelse(dfTrain5q$count>1,1,0)
dfTrain5$Group = ifelse(dfTrain5$count>1,1,0)

dfTrain5q$Inter_CountShop = dfTrain5q$Group*dfTrain5q$ShoppingMall
#dfTrain5q$Inter_CountFood = dfTrain5q$Group*dfTrain5q$Age Gets worse for Age and Foodcourt

train_x <- dfTrain5q %>%
  dplyr::select(-Transported, -count)
train_y <- dfTrain5q %>%
  dplyr::select(Transported)

dfTest6 <- dfTest5q
dfTest6$Transported = "1"

dfTest6$Group = ifelse(dfTest6$count>1,1,0)
dfTest6$Inter_CountShop = dfTest6$Group*dfTest6$ShoppingMall
#dfTest6$Inter_CountFood = dfTest6$Group*dfTest6$Age  

test_x <- dfTest6 %>%
  dplyr::select(-Transported,-PassengerID, -count)
test_y <- dfTest6 %>%
  dplyr::select(Transported)

#define final training and testing sets
xgb_train <- xgb.DMatrix(data = as.matrix(train_x), label = as.matrix(train_y))
xgb_test <- xgb.DMatrix(data = as.matrix(test_x), label = as.matrix(test_y))

#tRIAL AND ERROR GAVE 56 AS BEST with max.depth at 3 - COULD TRY OTHERS
#depth of 1000 and nrounds 100000 showed no double descent

model2 <- xgb.train(data = xgb_train, max.depth = 3, nrounds = 13)

#predictions_XGBoost <- EHModel_Predict(model2, xgb_test, predictionsColumnName = "Transported", testData_IDColumn = "PassengerID")

set.seed(100)
cv <- xgb.cv(data = xgb_train, nrounds = 100, nthread = 2, nfold = 10, metrics = list("rmse","auc"),
                  max_depth = 3, eta = 1, objective = "binary:logistic")
print(cv)
print(cv, verbose=TRUE)

# Check which round was the best iteration (the one that initiated the early stopping)
print(cv$best_iteration)

# Get the predictions
head(cv$pred)

# Train a model using 3 rounds (corresponds to best iteration)
trained_model <- xgb.train(data = xgb_train, max_depth = 3,
              eta = 1, nthread = 4, nrounds = 14,
              watchlist = list(train = xgb_train, eval = xgb_test),
              objective = "binary:logistic")
# Get predictions
head(predict(trained_model, xgb_train))

```

```{r}

predictions <- predict(trained_model,newdata=xgb_test)
predictions <- data.frame(as.vector(predictions)) 
predictions$PassengerId <- dfTest5$PassengerID
predictions[,c(1,2)] <- predictions[,c(2,1)]
colnames(predictions) <- c("PassengerID", "Transported")

predictions <- predictions %>%
  mutate(Transported=ifelse(Transported>.5,'True','False'))

#write_csv(predictions, "C:\\Users\\Eric\\Desktop\\XGBpredictions1.csv")
write_csv(predictions, "C:\\Users\\erico\\Desktop\\XGBpredictions_Rounds14.csv")

```

Neural network
```{r}

# https://www.r-bloggers.com/2021/04/deep-neural-network-in-r/

#takes too long
#n <- neuralnet(Transported ~ .,
#              data = dfTrain5,
#               hidden = c(12,7),
#               linear.output = F,
#               lifesign = 'full',
#               rep=1)
```
```{r}
#Needs above step

#plot(n,col.hidden = 'darkgreen',     
#col.hidden.synapse = 'darkgreen',
#     show.weights = F,
#     information = F,
#     fill = 'lightblue')

```
```{r}

data <- as.matrix(dfTrain5)
dimnames(data) <- NULL

```

Partition
```{r}
set.seed(123)
ind <- sample(2, nrow(data), replace = T, prob = c(.7, .3))
training <- data[ind==1,1:13]
test <- data[ind==2, 1:13]
trainingtarget <- data[ind==1, 14]
testtarget <- data[ind==2, 14]
str(trainingtarget)

```
Scaling
```{r}
m <- colMeans(training)
s <- apply(training, 2, sd)
training <- scale(training, center = m, scale = s)
test <- scale(test, center = m, scale = s)


```

```{r}

dfTrain5z <- dfTrain5 %>% dplyr::select(-starts_with('cabin'))

dfSmall2 <- dfSmall %>%
  dplyr::select(-Cabin1_T)
summary(dfSmall2)

pca <- prcomp(dfSmall2, center = TRUE,scale. = TRUE)

summary(pca)
plot(pca)
dfPCA <- as.data.frame(pca$x)
dfPCA2 <- cbind(Transported = dfSmall$Transported, dfPCA)

dfPCASmall <- dfPCA2 %>%
  dplyr::select(PC1, PC2, PC3, PC4, Transported)

dfSmallScaled <- EHPrepare_ScaleAllButTarget(dfSmall, "Transported")
```



```{r}
library(doParallel)

cl<-makePSOCKcluster(7)
  
registerDoParallel(cl)
  
start.time<-proc.time()
  
  rad <- EHModel_SVM(dfTrain5zz, "Transported", method="linear")
  
stop.time<-proc.time()
  
run.time<-stop.time -start.time
  
print(run.time)
  
stopCluster(cl)

```

```{r}
predictions_rad <- EHModel_Predict(rad$svm, dfTest5zz, predictionsColumnName = "Transported", testData_IDColumn = "PassengerID")

predictions_rad$Transported <- ifelse(predictions_rad$Transported==1,"True","False")
write_csv(predictions_rad, "C://Users//erico//Desktop//SVM_Lin.csv")

```



```{r}

getPrimeNumbers <- function(n) {  
   n <- as.integer(n)
   if(n > 1e6) stop("n too large")
   primes <- rep(TRUE, n)
   primes[1] <- FALSE
   last.prime <- 2L
   for(i in last.prime:floor(sqrt(n)))
   {
      primes[seq.int(2L*last.prime, n, last.prime)] <- FALSE
      last.prime <- last.prime + min(which(primes[(last.prime+1):n]))
   }
   which(primes)
}

library(doParallel)  
no_cores <- detectCores() - 2  
registerDoParallel(cores=no_cores)  
cl <- makeCluster(no_cores)  
result <- parLapply(cl, 10:1000000, getPrimeNumbers)  
stopCluster(cl)  


```


```{r}
library(doParallel)

cl<-makePSOCKcluster(7)
  
registerDoParallel(cl)
  
start.time<-proc.time()
  
nets <- function() {
  neuralnet(Transported ~ .,
               data = dfTrain5zz,
               hidden = 1,
               err.fct = "ce",
               linear.output = F,
               lifesign = 'full',
               rep = 2,
               algorithm = "rprop+",
               stepmax = 100000, likelihood=TRUE, )
}

nets()
  
stop.time<-proc.time()
  
run.time<-stop.time -start.time
  
print(run.time)

print("xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")
  
stopCluster(cl)

  
start.time<-proc.time()
  
  neuralnet(Transported ~ .,
               data = dfTrain5zz,
               hidden = 1,
               err.fct = "ce",
               linear.output = F,
               lifesign = 'full',
               rep = 2,
               algorithm = "rprop+",
               stepmax = 100000, likelihood=TRUE, )
  
stop.time<-proc.time()
  
run.time<-stop.time -start.time
  
print(run.time)



```


```{r}
# Load the parallel library
library(parallel)
library(neuralnet)

# Get the number of threads in the current machine
nThreads <- detectCores()
nThreads

# Initialise the cluster of threads
clusterOfThreads <- makeCluster(nThreads)

# Register the cluster of threads
#registerDoParallel(clusterOfThreads, cores=nThreads)

# Create a random set of nucleotide sequences

nets <- function() {
  
  neuralnet(Transported ~ .,
               data = dfTrain5zz,
               hidden = 2,
               err.fct = "ce",
               linear.output = F,
               lifesign = 'full',
               rep = 2,
               algorithm = "rprop+",
               stepmax = 1000000, likelihood=TRUE, )
  
}

# Use multiple threads to count how many times each nucleotide appears in each sequence
frequences <- clusterApply(cl=clusterOfThreads,
                           x=dfTrain5zz,
                           fun=nets)

# REMEMBER to close the cluster of threads
stopCluster(clusterOfThreads)

```


```{r}

library(neuralnet)
set.seed(42760)

dfTrain5zz$Transported = as.factor(dfTrain5zz$Transported)
dfScale <- EHPrepare_ScaleAllButTarget(dfTrain5zz, "Transported")

n <- neuralnet(Transported ~ .,
               data = dfScale,
               hidden = 2,
               err.fct = "ce",
               linear.output = F,
               lifesign = 'full',
               rep = 2,
               algorithm = "rprop+",
               stepmax = 100000, likelihood=TRUE, )

```

```{r}

plot(n, rep = 2)

```



```{r}
predicts <- predict(n, dfTest5zz)
predict_nn <- as.data.frame(predict(n, dfTest5zz)) %>%
  dplyr::select(V1) %>%
  dplyr::rename("Transported" = V1) %>%
  mutate(Transported=as.numeric(Transported)) %>%
  mutate(Transported=ifelse(Transported>.5,"True","False"))

predictions_nn2 <- cbind("PassengerID" = dfTest5zz$PassengerID, predict_nn)



predictions_nn <- EHModel_Predict(n, dfTest5zz, predictionsColumnName = "Transported", testData_IDColumn = "PassengerID")

predictions_nn2$Transported <- ifelse(predictions_nn2$Transported>.5,"True","False")
write_csv(predictions_nn, "C://Users//erico//Desktop//NN_3Layers.csv")

```

```{r}

predictions <- predict(n,newdata=dfTest5)
predictions <- data.frame(as.vector(predictions))
predictions$PassengerId <- dfTest5$PassengerID
predictions[,c(1,2)] <- predictions[,c(2,1)]
colnames(predictions) <- c("PassengerID", "Transported")

predictions <- predictions %>%
  mutate(Transported = ifelse(Transported>.5,"True","False"))

write_csv(predictions, "C:\\Users\\erico\\Desktop\\NNpredictions2.csv")

makePredictions2 <- function(model)
{
predictions <- predict(model,newdata=dfTest5)
predictions <- data.frame(as.vector(predictions))
predictions$PassengerId <- dfTest5$PassengerID
predictions[,c(1,2)] <- predictions[,c(2,1)]
colnames(predictions) <- c("PassengerID", "Transported")
write_csv(predictions, "C:\\Users\\erico\\Desktop\\SVMpredictions2.csv")
#write_csv(predictions, "D:\\RStudio\\CUNY_621\\Final\\predictionsABC.csv")
}

#makePredictions2(a$rf)
#makePredictions2(b$svm)
#makePredictions2(c)

```
```{r}



```







