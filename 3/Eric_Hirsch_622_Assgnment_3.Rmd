---
title: "SVM vs Random Forest - A Literature Review and Analysis"
subtitle: "CUNY 622 - Assignment 3" 
author: "Eric Hirsch"
date: "10/25/2022"
output:
  pdf_document:
    toc: true
    toc_depth: 5
---

### I. Essay

For this assignment we discuss the advantages and disadvantages of random forest versus SVM, both in the literature and in practice with the previous assignment’s data set. As a starting point, two example articles were offered which predicted Covid positive cases using decision tree ensembles and SVM, respectively.  

Because of the extreme imbalance between positive and negative cases, the authors of the decision tree ensemble article used decision tree ensembles specifically designed for imbalanced data sets (for example, balanced random forest).  Special sampling techniques were also applied to address the imbalance of the data set.  The best AUC score (.881) was achieved with RUSbagging.

The SVM article’s analysis was slightly more complex, in that it predicted whether a client had no infection, mild infection or serious infection. The model was effective, particularly in predicting severe cases, with an F1 score of .97. The article makes the claim that “SVM works best in predicting COVID-19 cases with maximum accuracy.” To support this claim, they performed a comparative study of supervised learning models, including Random Forest.  SVM achieved higher F1 scores than the others.

That SVM is the superior model in predicting Covid cases generally is a rather bold statement which can’t be justified by one study. There are too many variables – the particular kind and nature of the data collected for the study, the types and tunings of the machine learning algorithms (for example, this study did not consider the “ balanced” random forest algorithms that were featured in the first article), and the study design (such as breaking down the classes into no infection, mild or serious).

An examination of articles which compare SVM and random forest in the field of Geography (while I am no longer in this field, it’s where I got my education – Berkeley PhD 1996) do not show the superiority of one algorithm over the other.  Indeed, there is little consistency either for which algorithm is favored, or for how performance is to be predicted and compared.  For example, a study of multispectral images to predict canopy nitrogen weight in corn showed that random forests were only marginally better than SVR (Support Vector Regression) but that the concepts and analysis were easier to interpret with random forests  (Lee et al.). A study of groundwater mapping showed a higher AUC for random forest than for SVM tested with a linear, polynomial, sigmoid, and radial kernel  (Naghibi et al.).  Likewise, a study of sediment transport in the Tigris-Euphrates river also found that random forest predicted better than SVM (Al Mukhtar et al.).  

In contrast, a study predicting dominant tree species from Landsat images taken of the Krkonose mountains in the Czech Republic, found that SVM performed better than random forest in that particular study, but acknowledged that random forest consistently provided better results in other studies when spatial resolution was low, while SVM appeared to perform better when there were significantly more features (Zagajewski et al.).  A study of images by the satellite remote-sensing Sentinel-2A also found that SVM was most accurate (95.17%) (Kavzoglu et al.).

A systematic review conducted in 2020 of 250 peer-reviewed papers on remote-sensing image classification showed that despite some inroads from deep learning, SVM and random forest remained the two most popular image classification techniques, mainly due to lower computational complexity (Sheykhmousa et al.).  SVM is seen to be particularly effective where there is high dimensionality and limited training samples, while random forest is easier to use (fewer  hyper parameters to tune) and more flexible with more complex classifications. Both tend to be highly accurate, although, some  researchers still tout one or the other as the more superior without any strong basis.

As the researchers pointed out, SVM largely depends on the selection of the right kernel function – radial and polynomial tend to be popular in the remote-sensing field.  The binary nature of SVM also creates complications for its use in multiclass scenarios, which occur frequently in remote-sensing, although these can be overcome.  The ability of SVMs to manage small training sets and operate within high dimensional spaces (which is particularly applicable to remote-sensing image data) make SVMs attractive.

Random Forest, on the other hand, is popular because the decision-making process behind it is clearer and more understandable, it is easily implemented in parallel structure for geo-big data computing, it can handle thousands of input variables, is robust to outliers and noise, and is computationally lighter than other tree ensemble methods.

These recommendations echo those  of the machine learning literature. Both algorithms are … that random forest is better with … while SVM is better when …

Beyond these general recommendations, however, the superiority of one algorithm over the other may depend on the idiosyncrasies of the data set under examination.  It is wise to examine the performance of both before assuming one will perform better than the other.  We can illustrate this with the database from the previous assignment.

The database contains 466 records of small towns in the Northeast, together with statistics on poverty, industrialization, pollution, crime rate and so on. In the previous assignment, we performed regression analysis on the pupil teacher ratio (PT ratio) using random forest.  In this exercise we created a binary variable containing high PT ratio (the mean and above), and low PT ratio (below the mean) in order to run a more simple classification analysis.  We ran three support vector machines (linear, radial, and polynomial) as well as a random forest and a decision tree.  All of the algorithms were optimized for the parameters which may be tuned.

When all of the variables were included in the data set, random forest performed significantly better than SVM (98% AUC vs. 84% for SVM using a radial kernel). Even a simple decision tree yielded a higher AUC (85%).  

We investigated possible reasons that SVM performs more poorly in this data set.  It was found that for certain variables (pollution, e.g), there were anomalous cohorts that were driving the analysis. For example, there was a sizable cohort of schools all at a PT ratio of exactly 21. Further, all of the schools above a pollution index of .65 were in this cohort. 

Although pollution was barely linearly correlated with PT ratio (1.7), the random forest algorithm relied on it, as anomalies like these lend themselves well to a binary decision point.  The SVM algorithm (AUC=82%), which only looks at the support vectors, did not appear to benefit from this information. The evidence for this was that when the cohort was removed, the AUC for random forest dropped significantly while the AUC for SVM remained the same.  In addition, when the algorithms were run on a data set with minimal columns with much smoother distributions, radial SVM outperformed all of the other algorithms and polynomial SVM was second.

We also tested the assertion that SVM  performs better in high dimensional, low sample data by taking only every fifth record in the data set, reducing it to 94 rows with 12 columns. In this case, SVM does in fact approach, though does not overtake, Random Forest.  

This analysis shows that it’s important to test both algorithms in the data as the reason for the superiority of one performance over the other may not be readily apparent.  It can, however, be worthwhile to investigate further what it is about the data shape that favors one over the other.


Sources:

Al-Mukhtar, Mustafa. (2019) “Random Forest, Support Vector Machine, and Neural Networks to Modelling Suspended Sediment in Tigris River-Baghdad - Environmental Monitoring and Assessment.” SpringerLink, 25 Oct. 2019, link.springer.com/article/10.1007/s10661-019-7821-5.

Kavzoglu, Taskin, et al. (2020) “COMPARISON OF SUPPORT VECTOR MACHINES, RANDOM FOREST AND DECISION TREE METHODS FOR CLASSIFICATION OF SENTINEL - 2A IMAGE USING DIFFERENT BAND COMBINATIONS.” Conference: 41st Asian Conference on Remote Sensing (ACRS 2020), 9 Nov. 2020.

Lee, H. Wang, et al. (2022) Using Linear Regression, Random Forests, and Support Vector Machine With Unmanned Aerial Vehicle Multispectral Images to Predict Canopy Nitrogen Weight in Corn – DOAJ, doaj.org/article/70fb513d21214e4387057cba745e6c0d. Accessed 4 Nov. 2022.

Naghibi, S.A., Ahmadi, K. & Daneshi, (2017) A. Application of Support Vector Machine, Random Forest, and Genetic Algorithm Optimized Random Forest Models in Groundwater Potential Mapping. Water Resour Manage 31, 2761–2775 (2017). https://doi.org/10.1007/s11269-017-1660-3

Rienow, A, Mustafa, A, Krelaus, L, Lindner, C. (2021) Modeling urban regions: Comparing random forest and support vector machines for cellular automata. Transactions in GIS. 2021; 25: 1625– 1645. https://doi.org/10.1111/tgis.12756

Sheykhmousa, M. and Mahdianpari, M. (2020) Support Vector Machine vs. Random Forest for Remote Sensing Image Classification: A Meta-analysis and systematic review, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 

Zagajewski, Bogdan, et al. (2021) Comparison of Random Forest, Support Vector Machines, and Neural Networks for Post-Disaster Forest Species Mapping of the Krkonoše/Karkonosze Transboundary Biosphere Reserve – DOAJ, 7 Jan. 2021, doaj.org/article/e1836d4bb940454291eb1600f64afbd7.


### II. Analysis

In this part of the assignment we compare SVM to the Random Forest analysis we performed last week.

#### A. Description

```{r setup}
knitr::opts_chunk$set()
```

```{r}
library(tidyverse)
devtools::install_github("ericonsi/EHData")
library(ggsci)
library(EHData)
library(patchwork)
library(gridExtra)
library(caret)
library(pROC)
library(car)

```

```{r}

df1 <- read.csv("D:\\RStudio\\CUNY_622\\3\\CrimeRate.csv")

```

The data set consists of 466 observations of data realted to small towns in the North East. There are 11 numeric variables and two binary variables. There are no missing values. The variables include the level of industrialization, average tax rates, pollution levels, and so on. This data set is often used to predict crime rates, but we won’t use it for that purpose. 

These are the variables:

•	zn: proportion of residential land zoned for large lots (over 25000 square feet)\
•	indus: proportion of non-retail business acres per suburb\
•	chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0)\
•	nox: nitrogen oxides concentration (parts per 10 million)\
•	rm: average number of rooms per dwelling\
•	age: proportion of owner-occupied units built prior to 1940\
•	dis: weighted mean of distances to five Boston employment centers\
•	rad: index of accessibility to radial highways\
•	tax: full-value property-tax rate per $10,000\
•	ptratio: pupil-teacher ratio by town\
•	lstat: lower status of the population (percent)\
•	medv: median value of owner-occupied homes in $1000s\
•	crime: whether the crime rate is above the median crime rate (1) or not (0)

We will drop taxes (because they are 90% correlated with radial highways) and create a new binary variable, HighPTRatio (pupil teacher ratio above the mean = 1), so that we can perform a binary analysis.

#### B. The Relationship Between Distribution and Algorithm Effectiveness

When we examine histograms we see that a number of variables have distributions that are broken and uneven (zn, indus, nox and rad), suggesting possible hidden groupings. As we will see later, this may lend itself well to decision tree/random forest algorithms.  Many of the distributions are also skewed and we can see some likely outliers.  However, both models are robust to outliers so we don't do transformations here.
 
```{r}

library(psych)

a <- EHSummarize_SingleColumn_Histograms(df1)
grid.arrange(grobs=a, ncol=3, nrow=5)

```

When we examine some of these broken distributions further, we see the existence of idiosyncratic cohorts in the relationship with PTRatio. In particluar, when we look at a scatterplot for PTRatio on two broken distributions (nox and rad) vs two smooth ones (medv and rm), we see two distinctly different data shapes underlying this dataset.  This will become a factor later when it appears that Random Forest handles these idiosyncratic regions better than SVM, and that SVM handles the smoother regions better. 

```{r}


df2 <- df1 %>%
  dplyr:: select(-tax)

dfAll <- df2 %>%
  mutate(highPT = as.numeric(ifelse(ptratio>18.4, 1, 0))) %>%
    dplyr::select(-ptratio)

df3x <- dfAll %>%
  mutate(highPT = as.factor(highPT))

df3Nox <- dfAll %>%
  dplyr::select(highPT, nox)

g2 <- ggplot(df3x, aes(x=rad, y=nox, color=highPT)) +
  geom_point() +
    labs(title = str_wrap("Rad and Nox: Random Forest Performs Better", 5))

g3 <- ggplot(df3x, aes(x=rm, y=medv, color=highPT)) +
  geom_point() +
    labs(title = str_wrap("Rm and Medv: SVM Performs Better", 5))

grid.arrange(g2, g3, ncol=2)

```

#### C. Analysis

We prepare various datasets for analysis:

```{r}

  
dfRM_and_MEDV_only <- df2 %>%
  mutate(highPT= as.numeric(ifelse(ptratio>18.4, 1, 0))) %>%
  dplyr::select(highPT, rm, medv)

df3High_Nox_Filtered_Out <- dfAll %>%
  filter(nox<=.65)

df3Sparse <- dfAll %>%
 filter(row_number() %% 5 == 1) %>%
  dplyr::select(-chas)

df3CohortsLabeled <- dfAll %>%
  mutate(highNoxCohort = as.numeric(ifelse(nox>.65, 1, 0))) %>%
  mutate(highRadCohort = as.numeric(ifelse(rad>20, 1, 0)))


```
```{r}
RunAnalyses <- function(df, title="") {
  
devtools::install_github("ericonsi/EHData", force = TRUE)
library(EHData)
library("caret")
library(tidyverse)
library(ggsci)
library(EHData)
library(patchwork)
library(gridExtra)
library(pROC)
library(car)

dfq <- df

print (" ")
print ("SVM - LINEAR")
print (" ")
a <- EHModel_SVM(dfq, "highPT", method="linear", printPlot = FALSE,  printSVM = TRUE, printConfusionMatrix = TRUE)
print (" ")
print ("SVM - RADIAL")
print (" ")
b <- EHModel_SVM(dfq, "highPT", method="radial", printSVM =  TRUE, printPlot = FALSE, printConfusionMatrix = TRUE)
print (" ")
print ("SVM - POLY")
print (" ")
c <- EHModel_SVM(dfq, "highPT", method="poly", printPlot=FALSE, printSVM = TRUE, printConfusionMatrix = TRUE)
print (" ")
print ("SVM - RANDOM FOREST")
print (" ")
d <- EHModel_RandomForest(dfq, "highPT", categorical = TRUE, printPlot=FALSE, printRF = TRUE, printConfusionMatrix = TRUE)
print (" ")
print ("DECISION TREE")
print (" ")
e <- EHModel_DecisionTree(dfq, "highPT", categorical=TRUE, printDT=TRUE, printFancyTree = FALSE, printConfusionMatrix=TRUE)
#f <- EHModel_Regression_Logistic(dfq, "highPT")

#devtools::install_github("ericonsi/EHData", force = TRUE)
library(EHData)
  library(caTools)
  library(ROCR)

a1 <- EHCalculate_AUC_ForBinaryClasses(a$errors, printPlot=FALSE, printConfusionMatrix = FALSE)
b1 <- EHCalculate_AUC_ForBinaryClasses(b$errors, printPlot=FALSE, printConfusionMatrix = FALSE)
c1 <- EHCalculate_AUC_ForBinaryClasses(c$errors, printPlot=FALSE, printConfusionMatrix = FALSE)
d1 <- EHCalculate_AUC_ForBinaryClasses(d$errors, printPlot=FALSE, printConfusionMatrix = FALSE)
e1 <- EHCalculate_AUC_ForBinaryClasses(e$errors, printPlot=FALSE, printConfusionMatrix = FALSE)

tab <- matrix(c(a1$AUC, a1$ConfusionMatrix$overall["Accuracy"], b1$AUC, b1$ConfusionMatrix$overall["Accuracy"], c1$AUC, c1$ConfusionMatrix$overall["Accuracy"],d1$AUC, d1$ConfusionMatrix$overall["Accuracy"], e1$AUC, e1$ConfusionMatrix$overall["Accuracy"]), ncol=2, byrow=TRUE)
colnames(tab) <- c('AUC','Accuracy')
rownames(tab) <- c('SVM - linear','SVM - radial','SVM - poly', 'Random Forest', 'Decision Tree')
dfTab <- as.data.frame(tab) %>%
  arrange(desc(AUC))

q <- knitr::kable(dfTab, desc=TRUE, caption=title, digits=2)
q

return(q)

}

```

We run three varieties of SVM (linear, radial and poly), as well as Random Forest and Decision Tree on several datasets and compare performance. Hyperparameters have been tuned and algorithms maximized using a grid approach.

##### 1. The Full Dataset

```{r}

an1 <- RunAnalyses(dfAll, "Predicting PTRatio, Full Dataset")

```

```{r}

print(an1)
```


Both decision tree algorithms are the highest performers, with Random Forest showing 97% accuracy.  Rad and Nox figure prominently in the analysis.

##### 1. NOX Only

```{r}

an1a <- RunAnalyses(df3Nox, "Prediciting PTRatio: NOX Only")

```

```{r}

print(an1a)
```

Even using NOX alone, Random Forest achieves a 93% accuracy rate.

##### 2. High NOX Removed

```{r}

an2 <-RunAnalyses(df3High_Nox_Filtered_Out, "Predicting PTRatio: High Nox Removed")

```

```{r}

print(an2)

```


Now the performance for Random Forest drops considerably.  For SVM there is little change. SVM is now the second best algorithm.

##### 3. RM and MEDV Only

```{r}

an3 <-RunAnalyses(dfRM_and_MEDV_only, "Predicting PTRatio: RM and MEDV Only")

```

```{r}

print(an3)


```

With RM and MEDV, two smoothly distributed variables, SVM poly now performs best. Random Forest is worse than the other SVM algorithms.  That one decision tree performs better than random forest is probably a matter of luck - since random forest averages performance it stands to reason a particular decision tree may perform better than average.


Now the performance for Random Forest drops considerably.  For SVM there is little change. SVM is now the second best algorithm.

##### 4. Sparse Dataset

```{r}


an4 <-RunAnalyses(df3Sparse, "Predicting PTRatio: Sparse Dataset")

```

```{r}

print(an4)


```

With 20% of the dataset chosen at random, SVM's performance is a lot closer to Random Forest, though it still falls behind.


#### Conclusion\
\

The literature suggests that both algorithms may perfom well under different circumstances.  In this dataset, Random Forest performs better than SVM.  However, the literature does not generally point to exactly why one algorithm outperforms the other, unless the dataset is sparse or contains low-level imagery, etc.  The existence of many broken distributions and idiosyncratic cohorts may help to explain Random Forest's success in this dataset. When run on only the smoothly distributed data, SVM was superior.  This observation may not be generalizable, however - more resaerch would be needed to support it..

