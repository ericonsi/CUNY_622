---
title: "Eric_Hirsch_621_Assignment_4"
subtitle: "Predicting Insurance Claims" 
author: "Eric Hirsch"
date: "4/7/2022"
output:
  pdf_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning =  FALSE, message = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
devtools::install_github("ericonsi/EHData", force=TRUE)
library(EHData)
library(patchwork)
library(gridExtra)
library(ggsci)
library(caret)
library(pROC)
library(car)
library(psych)
library(patchwork)
library(tidytable)
library(MASS)
library(lubridate)
library(e1071)
library(caTools)
library(class)
#library(mice)
```
```{r}

df2 <- read.csv("D:\\RStudio\\CUNY_622\\1\\Salesdata_5000.csv")
#df2 <- read.csv("D:\\RStudio\\CUNY_622\\1\\Salesdata_50000.csv")

```

### 1. Data Exploration


#### A. Summary Statistics

```{r}

summary(df2)
str(df2)

df2$Item.Type <- factor(df2$Item.Type)

```


#### B. Distributions


##### 1. Boxplots

```{r}
a <- EHSummarize_SingleColumn_Boxplots(df2)
grid.arrange(grobs=a[1:7], ncol=4)

```

##### 2. Histograms

```{r}

df2$Item.Type <- as.character(df2$Item.Type)
EHSummarize_SingleColumn_Countplots(df2)
```
```{r}

EHSummarize_SingleColumn_Histograms(df2)

#grid.arrange(grobs=a2[c(1:7)], ncol=4)
```
```{r}

EHExplore_TwoCategoricalColumns_Barcharts(df2, "Item.Type")

```


```{r}

ggplot(df2, aes(Item.Type)) +
  geom_bar() +
  coord_flip()

```
```{r}

#EHExplore_TwoContinuousColumns_Scatterplots(df2,"Total.Revenue")
#EHExplore_OneContinuousAndOneCategoricalColumn_Boxplots(df2, "Revenue", yCategorical=TRUE)

ggplot(df2, aes(Item.Type, Unit.Cost)) +
  geom_boxplot() +
  coord_flip()

ggplot(df2, aes(Item.Type, Total.Profit)) +
  geom_boxplot() +
  coord_flip()
```

#### C. Multicollinearity

```{r}

df2Num <- df2 %>%
  dplyr::select_if(is.numeric)

EHExplore_Multicollinearity(df2Num)


```

### 2. Data Preparation

#### A. Create Dummy Variables


```{r}

df2$Order.Date2 <- as.Date(df2$Order.Date, format="%m/%d/%Y")
df2$Ship.Date2 <- as.Date(df2$Ship.Date, format="%m/%d/%Y")

df2$DateDiff <- as.integer(as.Date(df2$Ship.Date2)-as.Date(df2$Order.Date2))
df2$OrderDateNum <- as.integer(as.Date(df2$Ship.Date2)-as.Date("2000-01-01"))

ggplot(df2, aes(Item.Type, DateDiff)) +
  geom_boxplot() +
  coord_flip()
#Option: log of numerics
#df2$Units.Sold = log(df2$Units.Sold)
#df2$Total.Profit = log(df2$Total.Profit)

 #1. Most reasonable guess
df3 <- df2 %>%
    dplyr::select(-Order.Date, -Ship.Date, -Order.Date2, -Ship.Date2, -Country, -Order.ID, -Unit.Price, -Total.Revenue, -Total.Cost, -Unit.Cost)

#2 Include all
#df3 <- df2 %>%
#dplyr::select(-Order.Date, -Ship.Date, -Order.Date2, -Ship.Date2, -Country, -Order.ID)


#3 Minimal
#df3 <- df2 %>%
#  dplyr::select(-Order.Date, -Ship.Date, -Order.Date2, -Ship.Date2, -Country, -Order.ID, -Unit.Price, -Total.Revenue, #-Total.Cost, -Unit.Cost, -Item.Type, -DateDiff, -OrderDateNum, -Sales.Channel)

#Change Item.Type to a binary
#df3$Item.Type <- ifelse(df3$Item.Type=="Europe", "A", "B")

z=list("Item.Type")

df3a <- EHPrepare_CreateDummies(df3, exclude=z, dropFirst=TRUE)

df4 <- EHPrepare_ScaleAllButTarget(df3a, "Item.Type")


EHModel_Regression_Standard_Iterations(df4, "Total.Profit")
```
```{r}

# Splitting data into train
# and test data
split <- sample.split(df4, SplitRatio = 0.7)
train_cl <- subset(df4, split == "TRUE")
test_cl <- subset(df4, split == "FALSE")

```


```{r}

# Fitting KNN Model 
# to training dataset
#classifier_knn <- knn(train = train_cl,
#                      test = test_cl,
#                      cl = train_cl$Item.Type,
#                      k = 1)

```

```{r}


# Confusiin Matrix
#cm <- table(test_cl$Item.Type, classifier_knn)
#dfCM <- as.data.frame(cm)
  
```

```{r}

# Model Evaluation - Choosing K
# Calculate out of Sample error
#misClassError <- mean(classifier_knn != test_cl$Item.Type)
#print(paste('Accuracy =', 1-misClassError))
  
# K = 3
#classifier_knn <- knn(train = train_scale,
 #                     test = test_scale,
  #                    cl = train_cl$Item.Type,
   #                   k = 3)

```

```{r}

# create a list of 80% of the rows in the original dataset we can use for training
validation_index <- createDataPartition(df4$Item.Type, p=0.80, list=FALSE)
# select 20% of the data for validation
validation <- df4[-validation_index,]
# use the remaining 80% of data to training and testing the models
dataset <- df4[validation_index,]


EHSummarize_SingleColumn_Countplots(validation)

EHSummarize_SingleColumn_Countplots(validation)
validation %>% count(Item.Type)

```

```{r}

# Run algorithms using 10-fold cross validation
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

# a) linear algorithms
set.seed(47)
fit.lda <- train(Item.Type~., data=dataset, method="lda", metric=metric, trControl=control)
# b) nonlinear algorithms
# CART
# a) linear algorithms
set.seed(8)
#fit.qda <- train(Item.Type~., data=dataset, method="qda", metric=metric, trControl=control)
set.seed(7)
fit.cart <- train(Item.Type~., data=dataset, method="rpart", metric=metric, trControl=control)
# kNN
set.seed(7)
fit.knn <- train(Item.Type~., data=dataset, method="knn", metric=metric, trControl=control)
# c) advanced algorithms
# SVM
set.seed(7)
#fit.svm <- train(Item.Type~., data=dataset, method="svmRadial", metric=metric, trControl=control)
fit.glm <- train(Item.Type~., data=dataset, method="multinom", metric=metric, trControl=control)
fit.nb <- train(Item.Type~., data=dataset, method="nb", metric=metric, trControl=control)
fit.nnet <- train(Item.Type~., data=dataset, method="nnet", metric=metric, trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(Item.Type~., data=dataset, method="rf", metric=metric, trControl=control)
```

```{r}

#fit.glm <- train(Item.Type~., data=dataset, method="glm", metric=metric, trControl=control)
#summary(fit.glm)

```

```{r}

# Fit the model
model <- nnet::multinom(Item.Type ~., data = dataset)
# Summarize the model
summary(model)
# Make predictions
predicted.classes <- model %>% predict(validation)
head(predicted.classes)
# Model accuracy
mean(predicted.classes == dataset$Item.Type)

```


```{r}


# summarize accuracy of models
results <- resamples(list(lda=fit.lda, cart=fit.cart, nb=fit.nb, nnet=fit.nnet, multinom=fit.glm, knn=fit.knn, rf=fit.rf))
summary(results)
```

```{r}
# compare accuracy of models
dotplot(results)


```
```{r}

# summarize Best Model
print(fit.rf)
```
```{r}

# estimate skill of LDA on the validation dataset
predictions <- predict(fit.rf, validation)
x <- factor(validation$Item.Type)
confusionMatrix(predictions, x)

dfPred <- as.data.frame(predictions)
ggplot(dfPred, aes(predictions)) +
  geom_bar() +
  coord_flip()
```
